{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f1a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c16aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self,num_layers = 5, hidden_size = 60, output_size = 1, input_size = 1):\n",
    "        \n",
    "        super().__init__()\n",
    "        h = hidden_size\n",
    "        assert num_layers >=2\n",
    "        self.fc_u = nn.ModuleList()\n",
    "        self.ln_u = nn.ModuleList()\n",
    "#         self.fc_lambda = nn.ModuleList()\n",
    "#         self.ln_lambda = nn.ModuleList()\n",
    "        self.fc_u.append(nn.Linear(input_size, h))\n",
    "        self.ln_u.append(nn.Tanh())\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.fc_u.append(nn.Linear(h, h))\n",
    "            self.ln_u.append(nn.Tanh())\n",
    "        self.fc_u.append(nn.Linear(h, output_size))\n",
    "#         self.fc_lambda.append(nn.Linear(input_size, h))\n",
    "#         self.ln_lambda.append(nn.LayerNorm(h))\n",
    "        \n",
    "        \n",
    "#         for _ in range(num_layers - 2):\n",
    "#             self.fc_lambda.append(nn.Linear(h, h))\n",
    "#             self.ln_lambda.append(nn.Tanh())\n",
    "#         self.fc_lambda.append(nn.Linear(h, output_size))\n",
    "        \n",
    "#         self.fc_lambda.apply(lambda_weights_init)\n",
    "#         self.fc_u.apply(u_weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = self.u_net(x)\n",
    "#         lambda_val = self.lambda_net(x)\n",
    "        return u #, lambda_val\n",
    "\n",
    "    def u_net(self, x):\n",
    "        for i in range(len(self.fc_u) - 1):\n",
    "            layer = self.fc_u[i]\n",
    "            tanh = self.ln_u[i]\n",
    "            x = layer(x)\n",
    "            x = tanh(x)\n",
    "        x = self.fc_u[-1](x)\n",
    "        return x\n",
    "\n",
    "#     def lambda_net(self, x):\n",
    "#         for i in range(len(self.fc_lambda) - 1):\n",
    "#             layer = self.fc_lambda[i]\n",
    "#             tanh = self.ln_lambda[i]\n",
    "#             x = layer(x)\n",
    "#             x = tanh(x)\n",
    "            \n",
    "#         x = self.fc_lambda[-1](x)\n",
    "#         x = -torch.exp(x)\n",
    "#         return x\n",
    "    \n",
    "# def lambda_weights_init(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         torch.nn.init.normal_(m.weight, mean=-1 , std=0.4)  # Initialize weights with a normal distribution centered at -0.5\n",
    "#         m.bias.data.fill_(0.01)\n",
    "        \n",
    "# def u_weights_init(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         torch.nn.init.normal_(m.weight, mean=2, std=1)  # Initialize weights with a normal distribution centered at 2\n",
    "#         m.bias.data.fill_(0.01)\n",
    "\n",
    "def cal_u_exact(x):\n",
    "    # x = np.linspace(0,1,100)\n",
    "    u = torch.zeros_like(x)\n",
    "    cond1 = (x>=0) * (x< 1/(2*math.sqrt(2)))\n",
    "    cond2 = (x>= 1/(2*math.sqrt(2))) * (x< 0.5)\n",
    "    cond3 = (x>=0.5) * (x<1- 1/(2*math.sqrt(2)))\n",
    "    cond4 = (x>= ( 1 - 1/(2*math.sqrt(2)))) * (x<=1)\n",
    "    x1 = x[cond1]\n",
    "    x2 = x[cond2]\n",
    "    x3 = x[cond3]\n",
    "    x4 = x[cond4]\n",
    "    u[cond1] = (100 - 50 * math.sqrt(2)) *x1\n",
    "    u[cond2] = 100 * x2 * (1 - x2) - 12.5\n",
    "    u[cond3] = 100 * x3 * (1 - x3) - 12.5\n",
    "    u[cond4] = (100 - 50 * math.sqrt(2)) * (1 - x4)\n",
    "    # if config['visual'] == True:\n",
    "    # plt.plot(x,u);plt.show()\n",
    "    return u\n",
    "        \n",
    "def g(x):\n",
    "    # x = np.linspace(0,1,100)\n",
    "    out = torch.zeros_like(x)\n",
    "    cond1 = (x>=0) * (x<0.25)\n",
    "    cond2 = (x>= 0.25) * (x< 0.5)\n",
    "    cond3 = (x>=0.5) * (x < 0.75)\n",
    "    cond4 = (x>=0.75) * (x <= 1.0)\n",
    "    x1 = x[cond1]\n",
    "    x2 = x[cond2]\n",
    "    x3 = x[cond3]\n",
    "    x4 = x[cond4]\n",
    "    out[cond1] = 100 * x1**2\n",
    "    out[cond2] = 100 * x2 * (1 - x2) - 12.5\n",
    "    out[cond3] = 100 * x3 * (1 - x3) - 12.5\n",
    "    out[cond4] = 100 * (1 - x4)**2\n",
    "    # if config['visual'] == True:\n",
    "    #     plt.plot(x,g);plt.show()\n",
    "    return out\n",
    "\n",
    "\n",
    "def differentiable_heaviside(x, epsilon=1e-6):\n",
    "    return (torch.tanh(x / epsilon) + 1) / 2\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(u, x, g, gamma):\n",
    "    u_prime = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    u_doubleprime = torch.autograd.grad(u_prime, x, grad_outputs=torch.ones_like(u_prime), create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "#     loss = (10**(-3)) * torch.sum(torch.square(torch.min((- u_doubleprime + lambda_val), torch.zeros_like(- u_doubleprime - lambda_val))))\n",
    "#     loss = torch.sum(torch.square(torch.mul(torch.heaviside((u - g), values = torch.tensor([1.0])), u_doubleprime)))\n",
    "    \n",
    "    heaviside_approx = differentiable_heaviside(u - g)  # Use the differentiable Heaviside function\n",
    "    \n",
    "    loss = torch.sum(torch.square(torch.mul(heaviside_approx, u_doubleprime)))\n",
    "    \n",
    "    obstacle_term = torch.relu(g - u) #torch.min((u - g), torch.zeros_like(u - g))\n",
    "    loss += torch.sum(torch.square(obstacle_term))    \n",
    "#     loss += torch.sum(torch.square(lambda_val + (1/gamma) * torch.max(torch.zeros_like(u), g - gamma * lambda_val - u)))  # lambda = -(1/gamma) * max(0, u - gamma * lambda - g)\n",
    "    loss += (10**(3)) * torch.sum(torch.square(u[0]))\n",
    "    loss += (10**(3)) * torch.sum(torch.square(u[-1]))    \n",
    "\n",
    "    return torch.sum(loss)\n",
    "\n",
    "def train(model, x, g, gamma, epochs=6000, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        u = model(x)\n",
    "        \n",
    "        energy = loss_function(u, x, g, gamma)\n",
    "        loss = energy \n",
    "        loss.backward(retain_graph=True)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            \n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item()}\")\n",
    "            x_np = x.detach().numpy()\n",
    "            u_np = model.u_net(x).detach().numpy()\n",
    "            u_exact_np = cal_u_exact(x).detach().numpy()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.plot(x_np, u_np, label='Approximate Solution')\n",
    "            plt.plot(x_np, u_exact_np, label='Exact u(x)')\n",
    "#             plt.plot(x_np, g.detach().numpy(), label='Obstacle g(x)')\n",
    "#             plt.plot(x_np, lambda_np, label='Lambda Function')\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('u(x)')\n",
    "#             plt.title('Approximate Solution; '+f\"Epoch {epoch}/{epochs}, Loss: {loss.item()}\")\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "#         if loss < 3000:\n",
    "#             break\n",
    "\n",
    "\n",
    "x = torch.linspace(0, 1, 500).reshape(-1, 1)\n",
    "x.requires_grad_(True)\n",
    "\n",
    "gx = g(x)  # obstacle function\n",
    "gamma = 10\n",
    "\n",
    "model = PINN()\n",
    "\n",
    "\n",
    "\n",
    "train(model, x, gx, gamma)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
